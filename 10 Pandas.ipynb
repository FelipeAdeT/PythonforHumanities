{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas: Making the most of your Tabular Data\n",
    "\n",
    "(Adapted from [Eric Monson's taped workshops], see resources below)\n",
    "\n",
    "There are several ways one could structure CSV data, such as in lists of lists, combinations of dictionaries and lists, or numpy arrays, but the Pandas module provides an efficient functionality for working with tabular data (i.e., spreadsheets) such as .csvs or Excel files.\n",
    "\n",
    "We have seen the Pandas Dataframe in previous lessons; in this lesson, we learn how to access, analyze, restructure and visualize data within Dataframes.\n",
    "\n",
    "## Lesson Goals\n",
    "\n",
    "- **Import** .csv and Excel spreadsheets with Pandas\n",
    "- Assign row **indices**\n",
    "- Access information through **[]**, **.loc[]**,.iloc[] and recognize . notation\n",
    "- Select data within columns with conditionals\n",
    "- Perform math on columns and rows\n",
    "- Understand Tidy Data and pivot using **df.melt()**\n",
    "- Join and append tables through **df.merge()** and **df.append()**\n",
    "- Understand basics of **visualizing dataframes** in Pandas\n",
    "\n",
    "**Key Concepts:** DataFrame, Series, index, Tidy data, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import exercises for this lesson\n",
    "from QuestionsPandas import Q1, Q2, Q3, question, solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Files with Pandas\n",
    "\n",
    "Pandas works well for importing CSV files and Excel spreadsheets.\n",
    "\n",
    "We have imported CSVs before, in the 'Files' lesson of our course. As a refresher, the basic command is:\n",
    "\n",
    "```python\n",
    "file = pd.read_csv('filename.csv', 'r')\n",
    "```\n",
    "\n",
    "Where we are using the read_csv() method and assigning the object created to the variable 'file'.\n",
    "\n",
    "Similarly, Pandas has another command for importing Excel spreadsheets. Excel files have the added complication that they can hold many spreadsheets at once, so you may have to specify the sheet in question:\n",
    "\n",
    "```python\n",
    "file = pd.read_excel('file.xlsx', sheet_name= 'sheetname')\n",
    "```\n",
    "\n",
    "Let's import an Excel spreadsheet to use as an example for this lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "objects_table = pd.read_excel('Other_Files/NGAData.xlsx', sheet_name= 'objects')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exporting Files with Pandas\n",
    "\n",
    "Pandas allows us to export our dataframes into different types of files. Briefly, the commands for exporting to .csv, excel and .json files are as follows: \n",
    "\n",
    "### Saving to CSV\n",
    "\n",
    "```python\n",
    "df.to_csv('filename.csv',encoding='',index=False)\n",
    "```\n",
    "index=False to drop index (useful if index was autocreated)\n",
    "\n",
    "### Saving to Excel\n",
    "\n",
    "```python\n",
    "df.to_excel('filename.xlsx',sheet_name='sheet')\n",
    "```\n",
    "\n",
    "### Saving to JSON\n",
    "\n",
    "```python\n",
    "df.to_json('filename.json', orient='records')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An initial view of the DataFrame\n",
    "\n",
    "We can gauge the contents of the dataframe in a few ways, upon opening it. Pandas offers a few methods that can help.\n",
    "\n",
    "```df.head()``` and ```df.tail()``` allow us to see the first and last rows of the dataframe, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objects_table.head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objects_table.tail(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, this helps us get a first view of the dataframe, but our dataframe is too wide to show all  columns. We can generate a list of columns with  ```df.columns```.  \n",
    "\n",
    "**Note:** You might notice that this command does not have a parenthesis; that is because it is an attribute of the dataframe, not a method (function)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objects_table.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Pandas Dataframe\n",
    "\n",
    "> **Pandas Series:** One-dimensional container for string or numerical data. Each series has an index and potentially a name, as well as a data type.\n",
    "\n",
    "> **Pandas DataFrame:** Two-dimensional tabular structure with labels (rows and columns), where each column is a series.\n",
    "\n",
    "Columns in a Pandas DataFrame are each a Series, with a name (the column header) and an index.  Series are ordered by their index, so all columns are aligned by this common value, preserving the integrity of rows. \n",
    "\n",
    "One of the advantages of the DataFrame is that it allows us to store different types of values in different columns, including numbers, strings, and null values. Each column has a data type, which you can check using ``` df.dtypes```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objects_table.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specifying the index\n",
    "\n",
    "If you do not specify an index for rows, Pandas will create an integer index, as it did above (the column 'Unnamed:0')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objects_table.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also **specify an index**. They do not have to be numbers: they can be any identifier including integers, strings or dates. We can even use a column with non-unique values, but this might cause difficulties later on.\n",
    "\n",
    "There are two ways to specify an index: we can do so when we create the DataFrame, or after it has been created. \n",
    "\n",
    "To specify **when creating** the dataframe, add the following tag when using read_csv (or equivalent):\n",
    "\n",
    "```python\n",
    "df = pd.read_csv('filename.csv', index_col = 'col_name')\n",
    "```\n",
    "\n",
    "You can use the column's label or its position.\n",
    "\n",
    "To specify an index **after creating** the DataFrame, use:\n",
    "\n",
    "```python\n",
    "df = df.set_index('index_column_name')\n",
    "```\n",
    "\n",
    "By now, you should understand that we are reassigning the variable 'df' to this updated dataframe.\n",
    "\n",
    "Alternatively, using\n",
    "\n",
    "```python\n",
    "df.set_index('Year', inplace=True)\n",
    "```\n",
    "\n",
    "would allow us to forgo that reassignment.\n",
    "\n",
    "Let's specify our DataFrame's index as objectid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objects_table = objects_table.set_index('objectid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1** Use the code cell below to specify the same index using the 'inplace' tag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution(Q1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accessing Information in DataFrames\n",
    "\n",
    "Pandas dataframes align data using labels and integers. We can call data in a cell, column or row by using one of these two properties. \n",
    "\n",
    "There are different, overlapping ways to do this.\n",
    "\n",
    "We will focus on **square brackets** notation for making selections on **one axis**, and **.loc[]** for making selections specifying **two axes**, i.e. both rows and columns. Both these approaches allow us to insert single values, lists, ranges and conditional statements to create different types of selections. Additionally, the .loc[] notation can be used for single-axis selections, if combined with empty ranges (:), as explained below. \n",
    "\n",
    "We will also introduce a few other methods because you will encounter them in documentation and existing examples (and there are more!). But we recommend sticking to the methods developed in detail. \n",
    "\n",
    "## 1. One-dimensional indexing: **Square Brackets []**\n",
    "\n",
    "Using square brackets alone, you can perform selections of different types based on one dimension, columns.  It can get complex because it will yield differing output depending on what you put into the square brackets.\n",
    "\n",
    "### Square Brackets with Column Names\n",
    "\n",
    "To fetch a **single column**, simply specify the **column name** inside square brackets. \n",
    "\n",
    "```python\n",
    "df['column_name']\n",
    "```\n",
    "\n",
    "For instance, let's fetch the 'title' column from our dataframe using this notation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objects_table['title']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "One thing we might notice is that this is not formatted in the same way as our dataframe. Because our output is **one-dimensional**, pandas is outputting a **series**. If it were a single value it would output a single data point (such as a string or a number type). \n",
    "\n",
    "When we make a two-dimensional selection, it will output a dataframe.\n",
    "\n",
    "We might also notice that the output only displays a few rows. When fetched this way, Jupyter only exhibits the first and last few rows from the selection, but it has indeed fetched all of them. \n",
    "\n",
    "To access **multiple columns**, we can include a **list** of column names in our request. Recall that lists are bounded by square brackets, and its items separated by commas. \n",
    "\n",
    "This results in a -slightly odd- double-bracket notation:\n",
    "\n",
    "```python\n",
    "df[['column_1','column_2']]\n",
    "```\n",
    "\n",
    "Let's fetch the title and medium of all rows from our DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objects_table[['title','medium']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the output is indeed a dataframe.\n",
    "\n",
    "### Creating Copies from Bracket Selections\n",
    "\n",
    "Because of the complex structures underlying dataframes, using this method to create a new, temporary dataframe by variable assignment does not guarantee that you are acting on a copy or on the original. This will give you a warning message. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_medium = objects_table[['title','medium']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Message no longer appears-- did they fix this??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ensure that a copy is made, or to avoid the warning message, we have two options:\n",
    "\n",
    "One option is to put a .copy() at the end of our command:\n",
    "\n",
    "```python\n",
    "df[['column_1','column_2']].copy()\n",
    "```\n",
    "\n",
    "Or, better yet, use dataframe.loc(), explained later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Square Brackets with Ranges (Slicing)\n",
    "\n",
    "We can use slicing, as we did with lists and strings, to access ranges of rows within our data. \n",
    "\n",
    "```python\n",
    "df[a:b]\n",
    "```\n",
    "Will access rows a to b of our dataframe (all columns). Unlike with Python lists and strings, the start and end number are included. \n",
    "\n",
    "Let's put this to the test. In the cell below, fetch rows 1-20 in objects_table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objects_table[__]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also leave the start or end point blank, which will take everything from the beginning or to the end of the dataframe, respectively. \n",
    "\n",
    "In the cell below, fetch rows 0-100 by leaving part of the range blank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objects_table[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both approaches using square brackets can be placed side by side to make selections affecting rows and columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objects_table[0:100][['title','medium']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditional selections: Square brackets with a boolean series for multiple rows, all columns\n",
    "\n",
    "Using a boolean condition on a series returns a series of True/False values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objects_table['beginyear'] > 1600"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Knowning this, we can insert this into the square brackets nomenclature to make selections within a column. The syntax is a bit messy, requiring us to fully specify the condition, which requires calling the dataframe and column name together:\n",
    "\n",
    "```python\n",
    "df[df['columname']>0]\n",
    "```\n",
    "This will return only the rows for which the condition is true.\n",
    "\n",
    "So for instance, say we wanted to select all the columns for objects made after 1600:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objects_table[objects_table['beginyear']>1600]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above has returned 121,110 rows. \n",
    "\n",
    "We can make much more complex selections by including multiple conditions using bitwise operators for or (|) or and (&).\n",
    "\n",
    "Say we want to include only the objects begun in the 1600s:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objects_table[(objects_table['beginyear']>1600) & (objects_table['beginyear']<1700)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single-Axis selection alternative: Dot notation\n",
    "\n",
    "An alternative to bracket notation is to use dots to refer to columns:\n",
    "\n",
    "```python\n",
    "df.column_name\n",
    "```\n",
    "\n",
    "We do not recommend this system, but you will find it used in other code and should be able to recognize it. The syntax is used frequently because it saves some typing, but it has several issues. It does not work when:\n",
    "\n",
    "    - There are spaces in the column name\n",
    "    - The column name is the same as a Dataframe method (ex. count)\n",
    "    - The column name is a variable.\n",
    "    \n",
    "It is best to stick to the bracket notation.\n",
    "\n",
    "## 2. Two-Axis selection:  ```.loc[]``` using labels\n",
    "\n",
    "The options above were used to select data across one axis, for instance making a selection of columns or within columns. \n",
    "\n",
    "```.loc``` allows us to create selection conditions based on both rows and columns, using their labels (the column names and the row index).\n",
    "\n",
    "The basic structure is:\n",
    "\n",
    "```python\n",
    "df.loc[ rows, columns]\n",
    "```\n",
    "Where you supply information on the rows and columns you want to fetch. Like with square brackets, we can insert single values, lists, ranges and conditions into the brackets to create different types of selections. \n",
    "\n",
    "### Selecting a single cell with ```.loc[]```\n",
    "\n",
    "Simply, you give the coordinates of the cell in terms of its row and column:\n",
    "\n",
    "```python\n",
    "df.loc[row_index,'columname']\n",
    "```\n",
    "\n",
    "**Exercise 2** In the cell below, using loc notation, find the cell that gives the title of the object with id 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution(Q2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting a group of cells through .loc[] with lists\n",
    "\n",
    "You can supply lists for the rows and/or columns if you want to make a selection from several of them. This once again leads to the unsightly double bracket, but works well:\n",
    "\n",
    "```python\n",
    "df.loc[[row1,row2,row3],['column1','column5']]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objects_table.loc[[1,10,15],['title','medium']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting ranges of cells through .loc[] with slicing\n",
    "\n",
    "And, as we saw with lists and strings, we can also slice into a dataframe by giving ranges with a semicolon. \n",
    "\n",
    "```python\n",
    "df.loc[row1:row3, column1:column5]\n",
    "```\n",
    "As with other instances of slicing, you can leave the slice partly blank to grab from beginning/to end. A colon by itself means to grab the whole range, and can be used to perform a single-axis selection and consistently use the .loc[] notation throughout your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objects_table.loc[1:10,'title':'medium']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slicing into ranges works both for numerical indices as well as other labels, such as the column names. The selection will follow the order in which these labels appear in the dataframe, not an order based on their content. This can lead to non-intuitive results when the index is not sorted by value. We look at sorting further on in this lesson.\n",
    "\n",
    "We can also use an empty range for the rows or columns to select all, while still maintaining the .loc[] notation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objects_table.loc[:,'title']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditional selections with .loc[] and Boolean conditions\n",
    "\n",
    "Boolean series can be used in the manner described before to select from columns and rows. This is clearer perhaps than when used before, because we are explicit about both axes:\n",
    "\n",
    "```python\n",
    "df.loc[df['colname'] <  1, :]\n",
    "```\n",
    "\n",
    "In the example above, we create a condition on a column and select all rows that fulfil this condition. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objects_table.loc[objects_table['beginyear']>1900,:]\n",
    "# conditional example (with selection of subset of columns?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using conditionals with strings is a more efficient way to work on dataframes, rather than looping through columns.\n",
    "\n",
    "For instance, instead of using a for loop to ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two-axis selection alternative: ```df.iloc[]``` using integers\n",
    "\n",
    ".iloc[] works in a similar way to ```.loc[]```, but instead of supplying labels, we can supply positions. In that sense, it is less human-readable and may lead to more error.\n",
    "\n",
    "For instance, if we know that the 'title' column is in the 6th position, we can call the  cell in the 100th position. Notice that this is not the same as the cell we called in  the first .loc[] example, which we called by the index, id, at 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objects_table.iloc[100,6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Editing & Cleaning DataFrames\n",
    "\n",
    "Oftentimes, we will need to edit the columns and rows in a table in different ways. In this section, we will look at sorting dataframes, adding and removing columns, joining datasets and removing duplicate values, as well as simple math functions.  \n",
    "\n",
    "## Sorting Dataframes\n",
    "\n",
    "sort_values() is the method for sorting dataframes according to a column's contents. When applying this, we must note that it is not affecting the original dataframe. Thus, we either have to assign our modified dataframe to a variable or specify that we want the method to modify the original values.\n",
    "\n",
    "We should be familiar with assigning variables by now:\n",
    "\n",
    "```python\n",
    "df2= df2.sort_values('column') \n",
    "```\n",
    "\n",
    "In this case, we are reassigning the original dataframe variable to its new value, a common approach.\n",
    "\n",
    "Alternatively, through the in_place keyword, we can modify the dataframe directly.\n",
    "\n",
    "```python\n",
    "df2.sort_values('column, in_place = True) \n",
    "```\n",
    "\n",
    "The default is to sort by ascending order; to change to descending, we must specify ascending g=False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding and Removing columns\n",
    "\n",
    "To add a column, just call an unassigned column name with bracket notation and specify the desired value for all cells.\n",
    "\n",
    "```python\n",
    "df['newname'] = x\n",
    "```\n",
    "\n",
    "To remove a column, use the df.drop() method:\n",
    "\n",
    "```python\n",
    "df = df.drop('column_name', 1)\n",
    "```\n",
    "Once again, you have to reassign the variable or specify in_place=True.\n",
    "You must also specify the axis: 1 refers to columns, 0 to rows)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joining and Appending Datasets\n",
    "\n",
    "Often we will find ourselves with two related tables that we want to combine in order to analyze them together. We might have two tables with **different variables for the same observations**; in this case, we can **join** them. Joining two tables results in a table that adds variables (columns) to existing records. \n",
    "\n",
    "> Join: A join combines rows in one or more tables based on common values\n",
    "\n",
    "Alternatively, we might have two tables with the **same variables, and different observations**. In this case, we might want to add rows at the end of one table. For this, we **append** information to a DataFrame.\n",
    "\n",
    "> Appending adds rows with like columns to a table.\n",
    "\n",
    "### Joining Tables\n",
    "\n",
    "We can join two dataframes based on a common key: Python will identify rows in both tables with the same key and output a new table with variables from both tables for that key.\n",
    "\n",
    "There are 4 types of joins. Suppose we have two tables, left and right:\n",
    "\n",
    "|Types of Joins ||\n",
    "--------------|-----|\n",
    "|Left| Keeps all rows in the left table, and will join these to rows in right table with a matching key.|\n",
    "|Inner| Only gives us rows with matching in both tables (will also drop Left-only rows)|\n",
    "|Outer| Returns all rows from both tables, regardless of if they have a match.|\n",
    "|Right| Returns all rows in righ table, joined to any rows with a matching key from the left table.|\n",
    "\n",
    "Be conscientious about the type of join you employ, as it will determine  the table(s) from which you might lose records.\n",
    "\n",
    "The method for joining dataframes is ```df.merge()```, and it is specified in this way:\n",
    "\n",
    "```python\n",
    "df3 = df1.merge(df2, how='left', on='state')\n",
    "```\n",
    "The 'how' keyword specifies the type of join to execute, where df1 acts as the left table, and df2 acts as the right. \n",
    "\n",
    "The keyword 'on' determines the name of the common key. If the names of the key columns are not the same in both tables, you can use left_on and right_on to specify.\n",
    "\n",
    "Let's import some information to join to our objects_table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "people_table = pd.read_csv('Other_Files/NGAData/constituents.csv',low_memory=False)\n",
    "join_table = pd.read_csv('Other_Files/NGAData/objects_constituents.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These tables are from a relational database, and objects_table and people_table are intended to be merged with the join_table. The join table consists of rows with  identifiers from both tables, as well as some attributes that describe the relationship.\n",
    "\n",
    "So to relate 'objects' to 'people', we will have to realize two joins. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "join1 = objects_table.merge(join_table, how='left', on='objectid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3:** Edit the code cell below to perform the second join by linking our first joined table (join1) to the people_table using a 'left' join and the key called 'constituentid'. \n",
    "\n",
    "If you want to check your answer in a new cell by calling join2, note that the object information should be first, followed by the relationship, then the person. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "join2 = ____._____(______,how='____', on='______')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "join2 = join1.merge(people_table,how='left', on='constituentid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "join2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution(Q3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, if we make selections from the new table, we can make relating the contents of both tables.\n",
    "\n",
    "For instance, we can check the museum's holdings of works by a certain artist:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "join2[join2['constituentid']==1400][['title','preferreddisplayname']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appending Datasets\n",
    "\n",
    "To append datasets together, that is, to add one table as new rows in another, you need two tables with the same column structure.\n",
    "\n",
    "Then, you use the ```df.append()``` method:\n",
    "\n",
    "```python\n",
    "df1.append(df2)\n",
    "```\n",
    "\n",
    "This method also accepts dictionaries and other series, in lieu of a second dataframe. For more information, consult the [documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.append.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing duplicate values\n",
    "\n",
    "Another useful method, available for dataframes or series, is the option of finding only unique values.\n",
    "\n",
    "For the full dataframe, this is is done with the df.drop_values() method.\n",
    "\n",
    "```python\n",
    "df2 = df.drop_values('columnname')\n",
    "```\n",
    "This will return a selection of rows without repeating the values in the column.\n",
    "\n",
    "The series.unique() method will return a list of unique values within a single column:\n",
    "\n",
    "on\n",
    "df['clumn_name'].unique()\n",
    "```\n",
    "\n",
    "For instance, we can generate a list of artists represented in the NGA collection, and count them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artists = people_table[people_table['artistofngaobject']==1]['preferreddisplayname']\n",
    "artists = artists.unique()\n",
    "artists = artists.tolist()\n",
    "len(artists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Math on DataFrames\n",
    "\n",
    "Series and DataFrames have mathematical methods associated to them like ```sum()```,```mean()```, ```median()```,```max()```, ```min()```...\n",
    "\n",
    "In Pandas, math is applied efficiently to columns or rows. It is applied down columns by default. To act upon rows, you must specify otherwise by including axis=1 inside the parentheses.\n",
    "\n",
    "Strings are ignored or handled in a logical way. NaN/Null values are ignored by default, instead of causing errors.\n",
    "\n",
    "Dataframes have mathematical methods: \n",
    "\n",
    "```python\n",
    "df.sum()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0               6.665300e+04\n",
      "objectid                 8.346919e+04\n",
      "accessioned              9.999325e-01\n",
      "objectleonardoid         5.729338e+04\n",
      "locationid               8.192791e+03\n",
      "beginyear                1.856291e+03\n",
      "endyear                  1.867600e+03\n",
      "isiad                    1.369245e-01\n",
      "canshowimagery           9.643155e-01\n",
      "parentid                 1.022548e+05\n",
      "thumbnailsprohibited     3.568455e-02\n",
      "maxderivativeextent      4.471893e+03\n",
      "zoompermissiongranted    5.246311e-01\n",
      "isvirtual                2.145424e-03\n",
      "ispublic                 1.000000e+00\n",
      "locationcomponentid      8.246865e+04\n",
      "fingerprint              5.071287e+06\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(objects_table.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As do single columns, because they are series.\n",
    "\n",
    "```\n",
    "df['column'].sum()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1856.2910733102515"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(objects_table['beginyear'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# formatting the above two examples to be legible?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use operators to act upon values in columns. For instance:\n",
    "    \n",
    "```python\n",
    "df['newcolumn'] = df['column1'] + df['column2']\n",
    "```\n",
    "Which returns a series of answers (adds cells in same row)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.transpose()\n",
    "df.to_dict()\n",
    "df.to_numpy()\n",
    "df.to_json()\n",
    "df.to_csv()\n",
    "\n",
    "groupby"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Plotting with Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting functions\n",
    "\n",
    "Dataframes also come with the plot() method, which allows us to create different types of graphs. \n",
    "\n",
    "There are two ways to access the plot method, either including the graph type in parenthesis or including it with a dot:\n",
    "\n",
    "```python\n",
    "df.plot(kind='line', x='column', y=['column1', 'column2'])\n",
    "df.plot.line(x='column',y=['column1', 'column2'])\n",
    "```\n",
    "\n",
    "Plotting in Pandas is like plotting in excel: one column will be X values, all others will be Y. (Wide format, vs Tableau, Altair, Seaborn which require tall/tidy data: year in one column, field in another and one type of data per column. \n",
    "\n",
    "If we specify X in pandas, it will by default take all other columns for Y.\n",
    "\n",
    "; gets rid of text output before plot.\n",
    "\n",
    "\n",
    "# Bar Chart\n",
    "\n",
    "df.mean() (of each column)\n",
    "\n",
    "df.mean().plot.bar() vertical\n",
    "df.mean().plot.barh() horizontal\n",
    "\n",
    "Sorted bar charts\n",
    "vertical bar charts go left to right, horizontal from down to up\n",
    "\n",
    "df.mean().sort_values(ascending=False).plot.bar();\n",
    "\n",
    "df.mean().sort_values().plot.barh();\n",
    "\n",
    "# Histogram\n",
    "\n",
    "df.hist() gives you a grid of all your different columns and a histogram of each of those. 10 bins by default. Shows you all range by default, not consistent x-y values through graphs. There is an argument for same axis on all\n",
    "\n",
    "df.hist(sharex=True, sharey=True, layout(2,3), figsize=(10,5));\n",
    "\n",
    "Another way to do it is\n",
    "df.plot.hist()\n",
    "Gives you something different: one set of axes and bins, different colors for multiple columns. you can set the alpha value down to make transparent. \n",
    "\n",
    "# Box Plot\n",
    "\n",
    "df.plot.box()\n",
    "\n",
    "Sort works the same, but took median separately, sorted it and then used their index to create a sorted list of column names.\n",
    "\n",
    "horizontal box plot\n",
    "df.plot.box(vert=false) -- different from bar charts\n",
    "\n",
    "Syntax of plots are all slightly different, so powerful but there are better modules. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further Resources: \n",
    "    \n",
    "Eric Workshops:\n",
    "\n",
    "https://library.capture.duke.edu/Panopto/Pages/Viewer.aspx?id=28e9066b-d529-438e-9b23-aab600ef4e4a\n",
    "    \n",
    "[Eric Monson, _Python for Data Science: Pandas 102_](https://library.capture.duke.edu/Panopto/Pages/Viewer.aspx?id=b58ecfc9-c626-44da-aa77-ab5201548f09)\n",
    "\n",
    "[Eric Monson's Pandas & JupyterLab GitHub Repository](https://github.com/emonson/pandas-jupyterlab)\n",
    "        \n",
    "[Minimally Sufficient Pandas](https://medium.com/dunder-data/minimally-sufficient-pandas-a8e67f2a2428)\n",
    "\n",
    "[Pandas Cheatsheet](https://github.com/pandas-dev/pandas/blob/master/doc/cheatsheet/Pandas_Cheat_Sheet.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
