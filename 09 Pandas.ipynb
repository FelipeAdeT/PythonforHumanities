{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Navigation Reminder\n",
    "\n",
    "- **Grey cells** are **code cells**. Click inside them and type to edit.\n",
    "- **Run**  code cells by pressing $ \\triangleright $  in the toolbar above, or press ``` shift + enter```.\n",
    "-  **Stop** a running process by clicking &#9634; in the toolbar above.\n",
    "- You can **add new cells** by clicking to the left of a cell and pressing ```A``` (for above), or ```B``` (for below). \n",
    "- **Delete cells** by pressing ```X```.\n",
    "- Run all code cells that import objects (such as the one below) to ensure that you can follow exercises and examples.\n",
    "- Feel free to edit and experiment - you will not corrupt the original files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas I: Accessing and Exporting your Tabular Data\n",
    "\n",
    "(Adapted from Eric Monson's Pandas workshops, see resources below)\n",
    "\n",
    "There are several ways one could structure CSV data, such as in lists of lists, combinations of dictionaries and lists, or numpy arrays, but the Pandas module provides an efficient functionality for working with tabular data (i.e., spreadsheets) such as .csvs or Excel files.\n",
    "\n",
    "We have seen the Pandas Dataframe in previous lessons; in this lesson, we learn the many ways we can access data within Dataframes.\n",
    "\n",
    "---\n",
    "Questions and exercises are distributed throughout this lesson. Please run the code cell below to import them before starting the lesson. The code will not produce any visible output, but exercises and questions will be loaded for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import exercises for this lesson\n",
    "from QuestionsPandas import Q1, Q2, Q3, question, solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Lesson Goals\n",
    "\n",
    "- **Import** .csv and Excel spreadsheets with Pandas\n",
    "- Assign row **indices**\n",
    "- Access information through **[]**, **.loc[]**,.iloc[] and recognize . notation\n",
    "- Select data within columns with conditionals\n",
    "- **Export** spreadsheets as files\n",
    "\n",
    "**Key Concepts:** DataFrame, Series, index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Importing Files with Pandas\n",
    "\n",
    "Pandas works well for importing CSV files and Excel spreadsheets.\n",
    "\n",
    "We have imported CSVs before, in the 'Files' lesson of our course. As a refresher, the basic command is:\n",
    "\n",
    "```python\n",
    "file = pd.read_csv('filename.csv')\n",
    "```\n",
    "\n",
    "Where we are using the read_csv() method and assigning the object created to the variable 'file'.\n",
    "\n",
    "Similarly, Pandas has another command for importing Excel spreadsheets. Excel files have the added complication that they can hold many spreadsheets at once, so you may have to specify the sheet in question:\n",
    "\n",
    "```python\n",
    "file = pd.read_excel('file.xlsx', sheet_name='sheetname')\n",
    "```\n",
    "\n",
    "Let's import an Excel spreadsheet to use as an example for this lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "objects_table = pd.read_excel('Other_files/NGAData.xlsx', sheet_name= 'objects')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An initial view of the DataFrame\n",
    "\n",
    "We can gauge the contents of the dataframe in a few ways, upon opening it. Pandas offers a few methods that can help.\n",
    "\n",
    "```df.head()``` and ```df.tail()``` allow us to see the first and last rows of the dataframe, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objects_table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to specify the number of rows to view, we can include that number in the parentheses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objects_table.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, this helps us get a first view of the dataframe, but our dataframe is too wide to show all  columns. We can generate a list of columns with  ```df.columns```.  \n",
    "\n",
    "**Note:** You might notice that this command does not have a parenthesis; that is because it is an attribute of the dataframe, not a method (function)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objects_table.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Pandas Dataframe\n",
    "\n",
    "> **Pandas Series:** One-dimensional container for data. Each series has an index and potentially a name, as well as a data type.\n",
    "\n",
    "> **Pandas DataFrame:** Two-dimensional tabular structure with labels (rows and columns), where each column is a series.\n",
    "\n",
    "Columns in a Pandas DataFrame are each a Series, with a name (the column header) and an index. The index numbers are the labels for the entries within a series. These keep the columns aligned correctly into rows, preserving the integrity of the data. \n",
    "\n",
    "One of the advantages of the DataFrame is that it allows us to store different types of values in different columns, including numbers, strings, and null values. Each column has a data type, which you can check using ``` df.dtypes```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objects_table.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specifying the index\n",
    "\n",
    "If you do not specify an index for rows, Pandas will create an integer index, as it did above (the column 'Unnamed:0')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objects_table.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can **specify an index** from one of the columns of our dataframe. It do not have to be numbers: they can be any identifier including integers, strings or dates. We can even use a column with non-unique values, but this might cause difficulties later on.\n",
    "\n",
    "There are two ways to specify an index: we can do so when we create the DataFrame, or after it has been created. \n",
    "\n",
    "To specify an index **when creating** the dataframe, add the following argument when using read_csv (or equivalent):\n",
    "\n",
    "```python\n",
    "df = pd.read_csv('filename.csv', index_col='col_name')\n",
    "```\n",
    "\n",
    "To specify an index **after creating** the DataFrame, use:\n",
    "\n",
    "```python\n",
    "df = df.set_index('col_name')\n",
    "```\n",
    "\n",
    "By now, you should understand that we are reassigning the variable 'df' to this updated dataframe.\n",
    "\n",
    "Alternatively, using\n",
    "\n",
    "```python\n",
    "df.set_index('Year', inplace=True)\n",
    "```\n",
    "\n",
    "would allow us to forgo that reassignment.\n",
    "\n",
    "Let's specify our DataFrame's index as objectid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objects_table = objects_table.set_index('objectid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1** **Import** the csv from the file path Other_files/NGAData/constituents.csv as a DataFrame. **Analyze the DataFrame** using one of the methods previously introduced and **set an appropriate index using the inplace parameter**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "people_table = __________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution(Q1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accessing Information in DataFrames\n",
    "\n",
    "We can call data in a cell, column or row by using labels and indexes. Despite how basic this [] is, there are different, overlapping ways to do this, and these can cause some confusion. We will introduce the preferred methods for accessing data, as well as a few other methods because you will encounter them in documentation and existing examples (and there are more!). But we recommend sticking to the methods developed in detail. \n",
    "\n",
    "## 1. One-dimensional indexing: **Square Brackets []**\n",
    "\n",
    "Using square brackets alone, you can perform selections of different types based on one dimension, columns.  It can get complex because it will yield differing output depending on what you put into the square brackets.\n",
    "\n",
    "### Square Brackets with Column Names\n",
    "\n",
    "To fetch a **single column**, simply specify the **column name** inside square brackets. \n",
    "\n",
    "```python\n",
    "df['column_name']\n",
    "```\n",
    "\n",
    "For instance, let's fetch the 'title' column from our dataframe using this notation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objects_table['title']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "One thing we might notice is that this is not formatted in the same way as our dataframe. Because our output is **one-dimensional**, pandas is outputting a **Series**. If it were a single value it would output a single data point (such as a string or a number type). \n",
    "\n",
    "When we make a two-dimensional selection, it will output a dataframe.\n",
    "\n",
    "We might also notice that the output only displays a few rows. When fetched this way, Jupyter only exhibits the first and last few rows from the selection, but it has indeed fetched all of them. \n",
    "\n",
    "To access **multiple columns**, we can include a **list** of column names in our request. Recall that lists are bounded by square brackets, and its items separated by commas. \n",
    "\n",
    "This results in a -slightly odd- double-bracket notation:\n",
    "\n",
    "```python\n",
    "df[['column_1','column_2']]\n",
    "```\n",
    "\n",
    "Let's fetch the title and medium of all rows from our DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objects_table[['title','medium']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the output is indeed a DataFrame.\n",
    "\n",
    "### Creating Copies from Bracket Selections\n",
    "\n",
    "Because of the complex structures underlying dataframes, using this method to create a new, temporary dataframe by variable assignment does not guarantee that you are acting on a copy or on the original. When you perform operations on your supposed copy, it will give you a warning message. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_medium = objects_table[['title','medium']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_medium['title']=''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ensure that a copy is made, or to avoid the warning message, we should put a .copy() at the end of our command:\n",
    "\n",
    "```python\n",
    "df[['column_1','column_2']].copy()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_medium = objects_table[['title','medium']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_medium['title']=''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditional selections: Square brackets with a boolean series for multiple rows, all columns\n",
    "\n",
    "Using a boolean condition on a series returns a series of True/False values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objects_table['beginyear'] > 1600"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Knowing this, we can insert this into the square brackets nomenclature to make selections within a column. The syntax is a bit messy, requiring us to fully specify the condition, which requires calling the dataframe and column name together:\n",
    "\n",
    "```python\n",
    "df[df['columname']>0]\n",
    "```\n",
    "This will return only the rows for which the condition is true.\n",
    "\n",
    "So for instance, say we wanted to select all the columns for objects made after 1600:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objects_table[objects_table['beginyear']>1600]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above has returned 121,110 rows. \n",
    "\n",
    "We can make much more complex selections by including multiple conditions using the logical operators or (|) and and (&).\n",
    "\n",
    "Say we want to include only the objects begun in the 1600s:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objects_table[(objects_table['beginyear']>1600) & (objects_table['beginyear']<1700)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single-Axis selection alternative: Dot notation  (Not recommended)\n",
    "\n",
    "An alternative to bracket notation is to use dots to refer to columns:\n",
    "\n",
    "```python\n",
    "df.column_name\n",
    "```\n",
    "\n",
    "**We do not recommend this system**, but you will find it used in other code and should be able to recognize it. The syntax is used frequently because it saves some typing, but it has several issues. It does not work when:\n",
    "\n",
    "    - There are spaces in the column name\n",
    "    - The column name is the same as a Dataframe method (ex. count)\n",
    "    - The column name is a variable.\n",
    "    \n",
    "It is best to stick to the bracket notation.\n",
    "\n",
    "## 2. Two-Axis selection:  ```.loc[]``` using labels\n",
    "\n",
    "The options above were used to select data across one axis, for instance making a selection of columns or within columns. \n",
    "\n",
    "```.loc[]``` allows us to create selection conditions based on both rows and columns, using their labels (the column names and the row index).\n",
    "\n",
    "The basic structure is:\n",
    "\n",
    "```python\n",
    "df.loc[rows,columns]\n",
    "```\n",
    "Where you supply information on the rows and columns you want to fetch. Like with square brackets, we can insert single values, lists, ranges and conditions into the brackets to create different types of selections. \n",
    "\n",
    "### Selecting a single cell with ```.loc[]```\n",
    "\n",
    "Simply, you give the coordinates of the cell in terms of its row and column:\n",
    "\n",
    "```python\n",
    "df.loc[row_index,'columname']\n",
    "```\n",
    "\n",
    "**Exercise 2** In the cell below, using ```.loc[]``` notation, find the cell that gives the title of the object with id 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution(Q2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting a group of cells through .loc[] with lists\n",
    "\n",
    "You can supply lists for the rows and/or columns if you want to make a selection from several of them. This once again leads to the unsightly double bracket, but works well:\n",
    "\n",
    "```python\n",
    "df.loc[[row1,row2,row3],['column1','column5']]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objects_table.loc[[1,10,15],['title','medium']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting ranges of cells through .loc[] with slicing\n",
    "\n",
    "And, as we saw with lists and strings, we can also slice into a dataframe by giving ranges with a colon. \n",
    "\n",
    "```python\n",
    "df.loc[row1:row3, column1:column5]\n",
    "```\n",
    "As with other instances of slicing, you can leave the slice partly blank to grab from beginning/to end. A colon by itself means to grab the whole range, and can be used to perform a single-axis selection and consistently use the .loc[] notation throughout your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objects_table.loc[:,'title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 show where we are selecting a range of rows and a single column first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objects_table.loc[1:10,'title':'medium']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slicing into ranges works both for numerical indices as well as other labels, such as the column names. The selection will follow the order in which these labels appear in the dataframe, not an order based on their content. This can lead to non-intuitive results when the index is not sorted by value. We look at sorting further on in this lesson.\n",
    "\n",
    "We can also use an empty range for the rows or columns to select all, while still maintaining the .loc[] notation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditional selections with .loc[] and Boolean conditions\n",
    "\n",
    "Boolean series can be used in the manner described before to select from columns and rows. This is clearer perhaps than when used before, because we are explicit about both axes:\n",
    "\n",
    "```python\n",
    "df.loc[df['colname'] <  1, :]\n",
    "```\n",
    "\n",
    "In the example above, we create a condition on a column and select all rows that fulfil this condition. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objects_table.loc[objects_table['beginyear']>1900,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using conditionals with strings is a more efficient way to work on dataframes, rather than looping through columns. We will see this in Power Up Your Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two-axis selection alternative: ```df.iloc[]``` using integers\n",
    "\n",
    ".iloc[] works in a similar way to ```.loc[]```, but instead of supplying labels, we can supply positions. In that sense, it is less human-readable and may lead to more error.\n",
    "\n",
    "For instance, if we know that the 'title' column is in the 6th position, we can call the  cell in the 100th position. Notice that this is not the same as the cell we called in  the first .loc[] example, which we called by the index, id, at 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objects_table.iloc[100,6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exporting Files with Pandas\n",
    "\n",
    "Pandas allows us to export our dataframes into different types of files. Briefly, the commands for exporting to .csv, excel and .json files are as follows: \n",
    "\n",
    "### Saving to CSV\n",
    "\n",
    "```python\n",
    "df.to_csv('filename.csv',encoding='',index=False)\n",
    "```\n",
    "index=False to drop index (useful if index was autocreated)\n",
    "\n",
    "### Saving to Excel\n",
    "\n",
    "```python\n",
    "df.to_excel('filename.xlsx',sheet_name='sheet')\n",
    "```\n",
    "\n",
    "### Saving to JSON\n",
    "\n",
    "```python\n",
    "df.to_json('filename.json', orient='records')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Lesson Summary\n",
    "\n",
    "<div style=\"text-align:center\">    \n",
    "  <a href=\"08%20Functions.ipynb\">Previous Lesson: Functions</a>|\n",
    "   <a href=\"10%20Pandas%20II.ipynb\">Next Lesson: Pandas II</a>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
